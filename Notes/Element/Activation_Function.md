# Activation Function

Table of Content

* Linear
* Sigmoid
* Hyperbolic Tangent
* Rectified Linear Unit (ReLU)
* Leaky ReLU
* Softmax

## Linear

## Sigmoid

## Hyperbolic Tangent

## Rectified Linear Unit

## Leaky ReLU

## Softmax

## Resources

* [Wiki - Activation Function](https://en.wikipedia.org/wiki/Activation_function)

### Article

* [Medium - Deep Learning: Overview of Neurons and Activation Functions](https://medium.com/@srnghn/deep-learning-overview-of-neurons-and-activation-functions-1d98286cf1e4)
